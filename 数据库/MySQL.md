# 索引

BTree索引，哈希索引，全文索引 ，本文将只关注于BTree索引 

## 索引的数据结构及算法

> 在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。 

目前大部分数据库都采用B- tree或者B+ tree作为索引结构。

### B- Tree & B+ Tree

与B-Tree相比，B+Tree有以下不同点：

* 内节点不存储data，只存储key
* 叶子节点按顺序指向兄弟节点

**带有顺序访问指针的B+Tree** 

![image381](https://raw.githubusercontent.com/chenxiao19920206/other-picture/master/image381.png)

### 为什么使用B-Tree（B+Tree）

索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。 **换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。**

根据B-Tree的定义，可知检索一次最多需要访问h(h为tree的高度)个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。

**B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O(h)=O(logdN)。**一般实际应用中，出度d（d代表度，也就是一个节点存key/data的个数）是非常大的数字，通常超过100，因此h非常小（通常不超过3）。

>  而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。 

由上面分析，**d越大索引性能越好**。而出度的上限取决于节点内key和data的大小： 
$$
dmax = floor(pagesize / (keysize + datasize + pointsize))
$$
B+Tree非叶子结点不存储data，故B+ Tree的d更大，更适合**外存索引**。

除此之外选择B+Tree的理由是，**B+ Tree只要遍历叶子节点就可以实现整棵树的遍历**。而且在数据库中基于范围的查询是非常频繁的，而B- Tree不支持这样的操作 (或者说效率太低 )。

## MySQL索引实现

### MyISAM索引实现

MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。

下图是MyISAM索引的原理图： 

![myisam索引](https://raw.githubusercontent.com/chenxiao19920206/other-picture/master/myisam%E7%B4%A2%E5%BC%95.png)

可以看出MyISAM的索引文件仅仅保存数据记录的地址，数据单独保存在数据文件中。

**在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。** 

MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。 

### InnoDB索引实现

虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同：

* InnoDB的数据文件本身就是索引文件

  叶节点包含了完整的数据记录，这种索引叫做聚集索引。 

  因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有）。如果在创建表时没有显式定义主键，则InnoDB存储引擎会按如下方式选择或创建主键：

  - 首先判断表中是否存在非空的唯一索引（Unique NOT NULL），如果有，则该列即为主键
  - 如果不符合上述条件，InnoDB存储引擎会自动创建一个6字节大小的指针

  如果有多个非空唯一索引，将选择建表时**第一个定义的非空唯一索引**为主键。

* InnoDB的辅助索引data域存储相应记录主键的值而不是地址

  聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索**两遍索引**：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。

由此得知，**InnoDB中为什么不建议使用过长的字段作为主键**

因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。

**用非单调的字段作为主键在InnoDB中不是个好主意**

因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。 

### 两种存储引擎的不同点总结

|          | InnoDB                                                       | MyISAM                                             |
| :------: | ------------------------------------------------------------ | -------------------------------------------------- |
| 存储结构 | .frm存放表定义<br>.ibd 数据文件                              | .frm 表定义文件<br>.myd 数据文件 <br>.myi 索引文件 |
| 支持事务 | 支持ACID                                                     | 不支持                                             |
|    锁    | 表锁、行锁                                                   | 表锁                                               |
| count(*) | 全表扫描                                                     | 专门存储了行数                                     |
|   外键   | 支持                                                         | 不支持                                             |
|   CRUD   | 读写                                                         | 读多                                               |
|   主键   | 如果没有主键， 自动生成一个6字节的主键(用户不可见)<br>数据是主索引的一部分，附加索引保存的是主索引的值。 | 允许没有主键的表存在,索引都是保存行的地址          |

## 索引使用策略及优化

假设titles表的主索引为<emp_no, title, from_date> 

```sql
## 只有最左列精确匹配  -> 走索引，只用第一列前缀
SELECT * FROM employees.titles WHERE emp_no='10001';  
## 中间某个条件未提供  -> 走索引，只用第一列前缀
SELECT * FROM employees.titles WHERE emp_no='10001' AND from_date='1986-06-26';
## 没有指定索引第一列  -> 不走索引
SELECT * FROM employees.titles WHERE from_date='1986-06-26';
## 匹配某列前缀字符串  -> 走索引，只要%不出现开头就会走索引
SELECT * FROM employees.titles WHERE emp_no='10001' AND title LIKE 'Senior%';
## 范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。
SELECT * FROM employees.titles WHERE emp_no < '10010' and title='Senior Engineer';
## 查询条件中含有函数或表达式  -> 不走索引
SELECT * FROM employees.titles WHERE emp_no='10001' AND left(title, 6)='Senior';
SELECT * FROM employees.titles WHERE emp_no - 1='10000';
## 正则表达式  -> 不走索引
## 条件中带or关键字  -> 不走索引
## 字符串和数字比较  -> 不走索引
## 如果MySQL预估全表扫描比索引块  -> 不走索引
```

## 索引的选择

索引虽然加快了查询速度，但索引也是有代价的：索引文件本身要消耗存储空间，同时索引会加重插入、删除和修改记录时的负担，另外，MySQL在运行时也要消耗资源维护索引，因此索引并不是越多越好。 

一般下面几种情况不建议建索引 ：

* 表记录比较少，大约2000条记录以下就没有必要做索引
* 索引的选择性较低，Index Selectivity =Cardinality（不重复的索引值 ） / #T（表记录）， 越大越好
* 经常插入、删除、修改的表

有一种与索引选择性有关的索引优化策略叫做前缀索引，就是用列的前缀代替整个列作为索引key，当前缀长度合适时，可以做到既使得前缀索引的选择性接近全列索引，同时因为索引key变短而减少了索引文件的大小和维护开销 。比如：

使用<first_name>作为索引，Selectivity太低。<first_name, last_name> 作为索引，first_name和 last_name加起来的长度为30，则可以使用<first_name, left(last_name, 4)> 作为索引。具体last_name选择多少，可以测试Selectivity 值，以下为例：

```sql
SELECT count(DISTINCT(concat(first_name, left(last_name, 4))))/count(*) AS Selectivity FROM employees.employees;
+-------------+
| Selectivity |
+-------------+
|      0.9007 |
+-------------+
```

选择性已经很理想了，而这个索引的长度只有18 。

但是其缺点是不能用于**ORDER BY和GROUP BY**操作。

**在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。**

> 按照B+树的构造规则，使用自增索引会引起空间的浪费，每个节点浪费一半的空间，但Mysql的InnoDB引擎对自增索引做了优化：为每个索引页面维护了一个上次插入的位置以及上次插入是递增/递减的标识。根据这些信息，InnoDB能够判断出新插入到页面中的记录，是否仍旧满足递增/递减的约束，若满足约束，则采用优化后的分裂策略；若不满足，则使用B+树的分裂方式。[参考文章3]

### 关于索引的补充

1. **索引不会包含有NULL的列,避免表字段为null，建议设置默认值。** 只要列中包含有NULL值，都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此符合索引就是无效的。
2. **mysql一张表查询只能用到一个索引**。因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的，除非使用联合索引。
3. 不使用NOT IN 、or、！=操作，但<,<=，=，>,>=,BETWEEN,IN是可以用到索引的。 
4. 组合索引中有多个字段，其中一个字段是有范围判断，则需将此字段在最后面。 
5. 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可
6. 索引只能创建在表上，不能创建在视图上。
7. 使用exists代替in。

# MySQL优化

# 数据库范式

* 1NF 每个属性不可再分
* 2NF 没有部分依赖
* 3NF 没有传递依赖

# 数据库连接池

## 为什么我们需要数据库连接池？

* 减少连接创建时间
* 简化的编程模式 
* 控制资源的使用

## 数据库连接池策略

有些类似于Java线程池。当客户请求数据库连接时，按以下步骤进行：

1. 首先查看连接池中是否有空闲连接，如果存在空闲连接，则将连接分配给客户使用

2. 如果没有空闲连接，则查看当前所开的连接数是否已经达到最大连接数，如果没达到就重新创建一个连接给请求的客户；
3. 如果达到就按设定的最大等待时间进行等待，如果超出最大等待时间，则抛出异常给客户。

释放连接时，也需要判断以下：

当客户释放数据库连接时，先判断该连接的引用次数是否超过了规定值，如果超过就从连接池中删除该连接，否则保留为其他客户服务。

# 分库分表

## 基本概念

* **分表** 

按用户id % n,将大表拆成n个小表，n一般是2的幂。

* **分库**

分表能够解决单表数据量过大带来的查询效率下降的问题，但是，却无法给数据库的并发处理能力带来质的提升。 按数据库进行拆分，从而提高数据库写入能力。

* **垂直拆分**

将关联的表切分到数据库中，但不涉及到切分表的操作。

* **水平拆分**

将一个表的数据切分到不同的数据库中。

## 垂直拆分和水平拆分的坏处

* 垂直拆分
  * 单机的ACID被打破了。数据到了多机之后，原来在单机通过事务来进行的处理逻辑会受到很大的影响。我们面临的选择是：要么放弃单机事务，修改实现逻辑，要么引进分布式事务。
  * 一些join操作会变得比较困难，因为数据可能已经在两个数据库中了，需要应用或者其他方式解决。
  * 外键约束会受到影响。
* 水平拆分
  * 同样有ACID会被打破的情况
  * 同样有join操作被影响的情况
  * 外键约束会受到影响
  * 依赖单库的自增序列生成唯一ID会受影响
  * 针对单个逻辑意义上的表查询可能要跨库

## 如何解决分库分表带来的坏处

* ACID问题

  使用两阶段提交协议。分布式系统中增加了准备的阶段，但是引入两阶段的分布式事务会变得很复杂，在必要的情况下才建议使用。

* 水平拆分ID被破坏（递增ID）

  我们需要考虑ID的连续性和唯一性。如果只考虑唯一性，可以使用UUID，但UUID不连续，且索引较差。我们可以把所有ID集中放在一个地方进行管理，对每个ID序列独立管理，每台机器使用ID时都从这个ID生成器上进行获取。

* 跨库join

  在应用层把原来的join操作分成多次查询。也可以将常用的信息进行冗余，这样就可以变成单表查询。

* 外键约束问题

  比较难以解决，建议不要使用外键。

> 并不是分表就能够带来性能提升。例如：很多开发团队会认为含有1000W行的表是一张非常大的表，所以他们往往会采用分区，如对主键做10个HASH的分区，这样每个分区就只有100W的数据了，因此查询应该变快了，如```SELECT * FROM TABLE WHERE PK=@pk```。但是有没有考虑过这样一种情况：100W和1000W行的数据本身构成的B+树的层次都是一样的可能都是2层。那么上述走主键分区的索引并不会带来性能的提高。如果1000W的B+树高度是3,100W的B+树的高度是2，那么上述按主键分区的索引可以避免1次IO，从而提高查询效率。这没问题，但是这张表只有主键索引，没有任何其他的列需要查询的，如果还有类似如下的SQL语句：```SELECT * FROM TABLE WHERE KEY = @key```,这时对于KEY的查询需要扫描所有的10个分区，即使每个分区的查询开销为2次IO，则一共需要20次IO。而对于原来单表的设计，对于KEY的查询只需要2~3次IO。

# MySQL-InnoDB锁

## 并发事务带来的问题

  相对于串行处理来说，并发事务处理能大大增加数据库资源的利用率，提高数据库系统的事务吞吐量，从而可以支持可以支持更多的用户。但并发事务处理也会带来一些问题，主要包括以下几种情况。

- **更新丢失**（Lost Update）：当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题：
  - 第一类丢失更新：A事务撤销时，把已提交的B事务的数据覆盖掉。
  - 第二类丢失更新：A事务提交时，把已提交的B事务的数据覆盖掉。
- **脏读**（Dirty Reads）：一个事务正在对一条记录做修改，在这个事务并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”的数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做“脏读”。
- **不可重复读**（Non-Repeatable Reads）：一个事务在读取某些数据已经发生了改变、或某些记录已经被删除了！这种现象叫做“不可重复读”。
- **幻读**（Phantom Reads）：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。

## 三级封锁协议

- 一级封锁协议

  事务T在对数据A进行修改之前，必须对其加X锁，直至事务结束才释放。一级封锁协议可以防止丢失修改，并保证事务T是可恢复的。 但不能避免不可重复读和脏读。

- 二级封锁协议

  在一级封锁协议基础上增加事务T在读数据R之前必须先对其加S锁，读完后即可释放S锁。二级封锁协议出防止了丢失修改，还可以进一步防止读“脏”数据。 

- 三级封锁协议

  在一级封锁协议的基础上增加事务T在读数据R之前必须先对其加S锁，直到事务结束才释放。三级封锁协议出防止了丢失修改和读“脏”数据外，还可以进一步防止了不可重复读。 

可见，三级锁操作一个比一个厉害（满足高级锁则一定满足低级锁）。但有个非常致命的地方，一级锁协议就要在第一次读加x锁，直到事务结束。几乎就要在整个事务加写锁了，效率非常低。**三级封锁协议只是一个理论上的东西，实际数据库常用另一套方法来解决事务并发问题**。 

## 事务的隔离级别

mysql用意向锁（另一种机制）来解决事务并发问题，为了区别封锁协议，弄了一个新概念隔离性级别：包括Read Uncommitted、Read Committed、Repeatable Read、Serializable，一般默认Repeatable Read。 

在并发事务处理带来的问题中，“更新丢失”通常应该是完全避免的。但防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据**加必要的锁**来解决，因此，**防止更新丢失应该是应用的责任**。 

“脏读”、“不可重复读”和“幻读”，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决。数据库实现事务隔离的方式，基本可以分为以下两种。

一种是在读取数据前，对其加锁，阻止其他事务对数据进行修改。

另一种是不用加任何锁，通过一定机制生成一个数据请求时间点的一致性数据快照（Snapshot），并用这个快照来提供一定级别（语句级或事务级）的一致性读取。从用户的角度，好像是数据库可以提供同一数据的多个版本，因此，这种技术叫做数据多版本并发控制（ＭultiVersion Concurrency Control，简称MVCC或MCC），也经常称为多版本数据库。

​    数据库的事务隔离级别越严格，并发副作用越小，但付出的代价也就越大，因为事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然与“并发”是矛盾的，同时，不同的应用对读一致性和事务隔离程度的要求也是不同的，比如许多应用对“不可重复读”和“幻读”并不敏感，可能更关心数据并发访问的能力。

​    为了解决“隔离”与“并发”的矛盾，ISO/ANSI SQL92定义了４个事务隔离级别，每个级别的隔离程度不同，允许出现的副作用也不同，应用可以根据自己业务逻辑要求，通过选择不同的隔离级别来平衡＂隔离＂与＂并发＂的矛盾。

| 隔离级别/读数据一致性及允许的并发副作用 | 读数据一致性                             | 脏读 | 不可重复读 | 幻读 |
| --------------------------------------- | ---------------------------------------- | ---- | ---------- | ---- |
| 未提交读（Read uncommitted）            | 最低级别，只能保证不读取物理上损坏的数据 | 是   | 是         | 是   |
| 已提交度（Read committed）              | 语句级                                   | 否   | 是         | 是   |
| 可重复读（Repeatable read）             | 事务级                                   | 否   | 否         | 是   |
| 可序列化（Serializable）                | 最高级别，事务级                         | 否   | 否         | 否   |

最后要说明的是：各具体数据库并不一定完全实现了上述４个隔离级别，例如，Oracle只提供Read committed和Serializable两个标准级别，另外还自己定义的Read only隔离级别：SQL Server除支持上述ISO/ANSI SQL92定义的４个级别外，还支持一个叫做＂快照＂的隔离级别，但严格来说它是一个用MVCC实现的Serializable隔离级别。ＭySQL支持全部４个隔离级别，但在具体实现时，有一些特点，比如在一些隔离级下是采用MVCC一致性读，但某些情况又不是。 

## MySQL的行锁和表锁

先来说说什么是行锁和表锁。

- 表级锁：每次操作锁住整张表。开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低；
- 行级锁：每次操作锁住一行数据。开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高；
- 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

### 提一嘴**MyISAM的锁** 

　　a. MyISAM只有表锁，锁又分为读锁和写锁。　

| 当前锁模式/是否兼容/请求锁模式 | None | 读锁 | 写锁 |
| :----------------------------: | :--: | :--: | :--: |
|              读锁              |  是  |  是  |  否  |
|              写锁              |  是  |  否  |  否  |

　　b. 没有事务，不用考虑并发问题。

　　c. 由于锁的粒度太大，所以当该表写并发量较高时，要等待的查询就会很多了。

### InnoDB的行锁和表锁

没有特定的语法。mysql的行锁是通过索引体现的。

**如果where条件中只用到索引项，则加的是行锁；否则加的是表锁。**

锁的类型有两种：排它锁（X 锁）和共享锁（S 锁）。

* X锁

  如果事务T1对数据A加上了X锁，则只允许T1读取和修改A，其他任何事务都不能再对A加任何类型的锁，直到T1释放A上的锁为止。

* S锁

  如果事务T1对数据A加上了S锁，则事务T1可以读A但不能修改A，其他事务只能对A加S锁而不能加X锁，直到T1释放A上的S锁为止。

以上两种属于行锁，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁。

* 意向共享锁（IS）

  事务打算给数据行S锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。比如SELECT ... FROM T1 LOCK IN SHARE MODE语句，首先会对表T1加IS锁，成功加上IS锁后才会对数据加S锁。

* 意向排他锁（IX）

  事务打算给数据行加X锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。

  SELECT ... FROM T1 FOR UPDATE语句，首先会对表T1加IX锁，成功加上IX锁后才会对数据加X锁。

## 间隙锁（Next-Key锁）

​    当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙(GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制不是所谓的间隙锁（Next-Key锁）。

​    举例来说，假如emp表中只有101条记录，其empid的值分别是1,2,...,100,101，下面的SQL：

`SELECT * FROM emp WHERE empid > 100 FOR UPDATE`

​    是一个范围条件的检索，InnoDB不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101（这些记录并不存在）的“间隙”加锁。

​    InnoDB使用间隙锁的目的，一方面是为了防止幻读，以满足相关隔离级别的要求，对于上面的例子，要是不使用间隙锁，如果其他事务插入了empid大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；另一方面，是为了满足其恢复和复制的需要。有关其恢复和复制对机制的影响，以及不同隔离级别下InnoDB使用间隙锁的情况。

​    很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。

## 解决死锁的方法

###  死锁的预防

一次封锁法：要求每个事务必须一次性将所有要使用的数据全部加锁。

顺序封锁法：每个事务按照事先设定的顺序实施封锁。

两种方式的难度都很大，由此可见，**数据库不适合预防死锁**，只适合进行死锁的诊断与解除。

### 死锁的诊断与解除

* 超时法

  如果一个事物的等待时间超过了规定的时限，那么就认为其发生了死锁。规定的时间如果设置太短，那么会导致误判，太长会导致不能及时发现死锁。

* 事务等待图法

  事务等待图是一个有向图G=（T,U），T为节点集合，表示正在运行的事务；U为边的集合，如果T1等待T2，则在T1,T2之间画一条有向边，从T1指向T2。如果图中存在回路，则表示系统出现了死锁。

一旦检测到了死锁，通常的做法是选择一个处理死锁代价最小的事务，将其撤销，释放此事务持有的所有锁。当然，对撤销的事务所进行的修改必须加以恢复。

## 两段锁协议

* 申请不释放 在对任何数据进行读写操作之前，首先要申请并获得对该数据的封锁。
* 释放不申请 在释放一个锁之后，事务不再申请和获得任何其他封锁。

所谓两段锁的含义是，事务分为两个阶段：第一个阶段是获得封锁，事务可以申请获得任何数据项上的任何类型的锁，但不能释放锁；第二个阶段是释放封锁，事务可以释放任何数据项上的任何类型的锁，但是不能再申请任何锁。

若所有事务均遵守两段锁协议，则这些事务的所有交叉调度都是可串行化的。 

### 两段锁协议与防止死锁的一次封锁法的区别：

一次封锁法要求事务必须一次对所有要使用到的数据项进行加锁，否则不能继续运行。显然，一次封锁法符合两段锁协议，但是两段锁协议并不要求一次就要对所有需要用到的数据项进行加锁，因此遵守两段锁协议的事务有可能死锁。

## 对于InnoDB锁的总结

1. InnoDB的行销是基于索引实现的，如果不通过索引访问数据，InnoDB会使用表锁。
2. InnoDB间隙锁机制，以及InnoDB使用间隙锁的原因。
3. 在不同的隔离级别下，InnoDB的锁机制和一致性读策略不同。
4. ＭySQL的恢复和复制对InnoDB锁机制和一致性读策略也有较大影响。
5. 锁冲突甚至死锁很难完全避免。

# 查询性能优化

1. 最好不要使用```select *```。解决方案是查询需要的列。
2. 重复查询相同的数据。解决方案是查询之后缓存起来。
3. 大查询拆分成几个小查询，尤其是拆分join语句，拆成单表查询。
   * 缓存命中更高
   * 减少锁的竞争

# 其他问题

## char varchar text区别

* **char**

  char最大长度是255字符，注意是**字符数**和**字符集**没关系。可以有默认值，尾部有空格会被截断。 

* **varchar** 

   varchar的最大长度65535是指能存储的字节数，其实最多只能存储65532个字节，还有3个字节用于存储长度。注意是**字节数**这个和**字符集**有关系。一个汉字字符用utf8占用3字节，用gbk占用2字节。可以有默认值，尾部有空格不会截断。 

* **text** 

  text和varchar基本相同。text会忽略指定的大小这和varchar有所不同，text不能有默认值。尾部有空格不会被截断。text使用额外的2个字节来存储数据的大小，varchar根据存储数据的大小选择用几个字节来存储。text的65535字节全部用来存储数据，varchar则会占用1－3个字节去存储数据大小。

## Mybatis中#和$区别

|          | #                                      | $                                        |
| -------- | -------------------------------------- | ---------------------------------------- |
| 特殊处理 | 默认当成字符串                         | 不会做特殊处理，经常作用于表名、order by |
| 预编译   | 占位符，以？代替，真正查询时才会带入值 | 简单替换，直接显示生成sql中              |
| sql注入  | 可以防止                               | 不能防止                                 |

## 自增主键的优缺点

* 优点
  * 数据库自动编号，速度快，而且是增量增长，按顺序存放，对于检索非常有利。
  * 数字型，占用空间小，易排序，在程序中传递也方便； 
  * 如果通过非系统增加记录时，可以不用指定该字段，不用担心主键重复问题。  
* 缺点
  * 当数据库导出之后重新导入（备份再恢复），主键会重新生成，如果有其他的表以这个主键作为外键，那么会导致这个关联关系不存在。

# 复制的原理

1. 主库将所有操作都记录到binlog中。当复制开启时，主库的DUMP线程根据从库IO线程的请求将binlog中的内容发送到从库。
2. 从库的IO线程接受到主库DUMP线程发送的binlog事件后，将其写到本地的中继日志（relay-log）。
3. 从库的SQL线程重放relay-log中的事件。

原理图：

![](https://images2015.cnblogs.com/blog/576154/201608/576154-20160815105653984-1386637818.jpg)

* 基于语句的复制

  在MySQL5.0及之前的版本中只支持基于语句的复制（也叫逻辑复制），主库会记录那些造成数据更改的查询，当备库读取并重放这些事件时，实际上只是把主库上执行的SQL再执行一遍。

  好处是实现简单，很容易理解（因为是sql语句，全场通用）。坏处是存在一些无法被正确复制的SQL语句，比如依赖当前时间戳的语句，以及对于一些存储器或者触发器，并不能正确复制sql语句。

* 基于行的复制

  5.1开始支持，最大的好处是正确复制每一行。但有时候代价很高，比如执行：```update table set col1=0```,由于这条语句做了全表更新，故使用语句复制的效率更高。坏处也很明显，过程就是一个黑盒子，你无法知道服务器正在做什么，如果出现问题，很难找到问题的所在。

没有哪种方式是完美的，MySQL可以在两种复制模式间动态切换，默认情况下使用的是基于语句的复制方式，但是如果发现语句无法被正确复制，就切换到行复制模式。

# 高可用

高可用使用百分比表示，100%的可用性是不可能达到的。“5个9”表示99.999%的正常可用时间已经很高了（即每年只允许5分钟的宕机时间）。但所花的成本确实巨大的，从“5个9”到“6个9”的花费可能远超之前。但，幸运的是，2个9或者3个9并不困难。

## 如何实现高可用性

* 避免导致宕机的原因来减少宕机时间
  * 确认基本的服务器配置是正确的
  * 避免使用复杂的特性，比如触发器
  * 监控重要的组件，比如磁盘、CPU、内存等
  * 定期检查复制完整性
* 尽量保证在发生宕机时能够恢复
  * 避免单点失效
    * 主从备份，备库需要必须在线并一直执行查询（可由主库分出一部分查询给备库），而不仅仅是备用，因此他们是“预热”过的，随时处于可用的状态。
    * 主主备份
    * 采用集群，并使用均衡负载方案，如果一台服务器失效，其他服务器可以接管他的负载
    * 冗余组件：空闲的网卡、路由器等等硬件
    * 备份数据库文件
  * 中间件

# 参考文章

1. [MySQL索引背后的数据结构及算法原理](http://blog.jobbole.com/24006/)
2. [从B树、B+树、B*树谈到R 树](https://blog.csdn.net/v_july_v/article/details/6530142)
3. [浅谈B+树索引的分裂优化](http://hedengcheng.com/?p=525)
4. 《高性能MySQL》